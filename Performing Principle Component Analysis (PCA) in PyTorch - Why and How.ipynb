{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5dbc383b-15aa-4f2d-a4df-2dcf1ba116f1",
   "metadata": {},
   "source": [
    "To Read the connected blog, click the link below:\n",
    "\n",
    "[Performing Principle Component Analysis (PCA) in PyTorch: Why and How](https://medium.com/@megha.natarajan/performing-principle-component-analysis-pca-in-pytorch-why-and-how-777cfcde032a)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e9e85aa-cded-4e4b-82ac-5464fd0f55e4",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Why You Might Want to Use PyTorch for PCA: Beyond Deep Learning\n",
    "\n",
    "We often hear about PyTorch in the context of deep learning and neural networks. Given its dynamic computation graph and GPU-accelerated tensor operations, it’s undoubtedly a powerhouse for those applications. But when it comes to tasks like Principal Component Analysis (PCA), many might instinctively turn to specialized libraries like Scikit-learn. And for a good reason! Libraries like Scikit-learn offer optimized implementations and a user-friendly interface for PCA and other data analysis tasks.\n",
    "\n",
    "However, there are scenarios where using PyTorch for PCA makes not just sense, but is actually highly recommended. Let’s delve into some of these use cases.\n",
    "\n",
    "## 1. Handling Large-scale Data with GPU Acceleration\n",
    "When dealing with vast datasets, the ability to use GPU acceleration can be a game-changer. PyTorch’s native support for CUDA allows for swift operations, especially beneficial for the matrix computations involved in PCA.\n",
    "\n",
    "## 2. Deep Learning Data Preprocessing\n",
    "If you’re already swimming in the deep waters of PyTorch for neural network training, it’s convenient to stay in the same environment for preprocessing. Using PCA as a preprocessing step can sometimes help improve model performance, especially in reducing overfitting on features with minor variance.\n",
    "\n",
    "## 3. Visualizing High-Dimensional Activations\n",
    "Ever wondered what goes on inside those deep neural layers? By using PCA to reduce the high-dimensional activations from neural network layers to a 2D or 3D space, you can visualize and interpret the patterns more easily. Keeping this within PyTorch ensures a smoother transition between model inspection and visualization.\n",
    "\n",
    "## 4. Feature Extraction and Transfer Learning\n",
    "Leveraging pre-trained models for feature extraction is a powerful strategy. However, the resulting feature vectors can be high-dimensional. Applying PCA can compactly capture the essence of these features, making them more manageable and interpretable.\n",
    "\n",
    "## 5. Experimental Neural Network Layers\n",
    "For those who love tinkering with novel architectures, integrating PCA-like operations within custom neural network layers can lead to intriguing results. With PyTorch’s flexible nature, experimenting becomes a more seamless experience.\n",
    "\n",
    "## 6. Hybrid Models: Bridging Traditional and Neural Approaches\n",
    "Building models that marry classical dimensionality reduction techniques with neural components? Implementing everything in PyTorch ensures a consistent workflow and can help avoid unwanted hiccups that come from switching between different libraries.\n",
    "\n",
    "## 7. For the Researchers and the Curious Minds\n",
    "PyTorch, with its dynamic computation graph, is a playground for experimentation. If you’re exploring new variations of PCA or investigating its deeper ties with neural networks, PyTorch provides the flexibility to experiment and iterate rapidly.\n",
    "\n",
    "In a nutshell, while specialized libraries offer excellent tools for PCA in most data analysis scenarios, it’s essential not to overlook the benefits of a deep learning framework like PyTorch, especially when the tasks are intertwined with neural computations. As with many things in the data science realm, the right tool often depends on the context. And sometimes, that tool just might be PyTorch.\n",
    "\n",
    "Having understood the advantages of using PyTorch for PCA, let’s dive into the steps to implement it with this powerful framework.\n",
    "\n",
    "## Quick Refresher — What is PCA?\n",
    "At its core, PCA is a method used to emphasize variation and bring out strong patterns in a dataset. It transforms the original variables into a new set of variables, which are linear combinations of the original variables. These new variables, or “principal components,” are orthogonal (perpendicular in n-dimensional space) and capture the maximum variance in the data.\n",
    "\n",
    "Imagine a cloud of data points scattered in a three-dimensional space. While these points might not lie perfectly on a flat surface, they might approximately lie on a plane. PCA helps find this plane and even compresses the 3D space into 2D by projecting the points onto this plane.\n",
    "\n",
    "There are several reasons why PCA is so widely employed:\n",
    "\n",
    "- **Data Visualization**: High-dimensional data is challenging to visualize. PCA reduces the number of dimensions, making it easier to plot and interpret the data.\n",
    "- **Noise Reduction**: By keeping components that capture the most variance and eliminating others, PCA can help reduce the noise present in the dataset.\n",
    "- **Improved Efficiency**: High-dimensional data can be computationally intensive for machine learning algorithms. PCA can accelerate the training process by reducing the number of dimensions.\n",
    "\n",
    "In essence, PCA provides a simpler, lower-dimensional view of your data, making it a valuable tool for both data visualization and machine learning.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8cd4b005-0d0c-4899-88fc-f859f66ebf13",
   "metadata": {},
   "source": [
    "# Performing Principal Component Analysis (PCA) in PyTorch\n",
    "\n",
    "Principal Component Analysis (PCA) is a dimensionality reduction technique commonly used in machine learning and data visualization. In this guide, we'll walk through how to perform PCA using PyTorch, a popular deep learning library.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6351b88c-4668-4844-939d-c6e622bd463d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-10-10T04:25:54.662981Z",
     "iopub.status.busy": "2023-10-10T04:25:54.662652Z",
     "iopub.status.idle": "2023-10-10T04:25:54.666544Z",
     "shell.execute_reply": "2023-10-10T04:25:54.665507Z",
     "shell.execute_reply.started": "2023-10-10T04:25:54.662957Z"
    },
    "tags": []
   },
   "source": [
    "## 1. Import Necessary Libraries\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "96b224be-7fe7-4da8-a55b-ac98196b11cf",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-10-10T04:40:00.809032Z",
     "iopub.status.busy": "2023-10-10T04:40:00.808560Z",
     "iopub.status.idle": "2023-10-10T04:40:09.918228Z",
     "shell.execute_reply": "2023-10-10T04:40:09.917605Z",
     "shell.execute_reply.started": "2023-10-10T04:40:00.809006Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import torch\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2cb64b1a-08a9-4337-8c8e-361c9dfc4610",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-10-10T04:19:35.595619Z",
     "iopub.status.busy": "2023-10-10T04:19:35.595083Z",
     "iopub.status.idle": "2023-10-10T04:19:35.603688Z",
     "shell.execute_reply": "2023-10-10T04:19:35.601895Z",
     "shell.execute_reply.started": "2023-10-10T04:19:35.595577Z"
    }
   },
   "source": [
    "## 2. Center the Data\n",
    "\n",
    "Before diving into PCA, we must first center our data. This means subtracting the mean from each feature so that it's centered around zero.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "39da6727-09fa-4087-908e-0340f8e98a56",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-10-10T04:40:35.834321Z",
     "iopub.status.busy": "2023-10-10T04:40:35.833965Z",
     "iopub.status.idle": "2023-10-10T04:40:35.842290Z",
     "shell.execute_reply": "2023-10-10T04:40:35.841597Z",
     "shell.execute_reply.started": "2023-10-10T04:40:35.834294Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.8501, -1.6765, -1.3068,  0.9928, -1.2914,  0.3963,  0.8872,  0.0899,\n",
       "         -0.3167,  2.1305],\n",
       "        [ 0.8715, -0.4769,  1.3075,  0.6764,  1.4339,  0.1620,  0.9954, -0.0725,\n",
       "         -1.3559, -0.1502],\n",
       "        [ 0.8957, -1.5106,  0.1809,  0.7641, -0.3624,  0.5002, -0.7553, -2.3242,\n",
       "          0.7902,  0.4804],\n",
       "        [-0.1688,  0.6611, -0.4735, -0.9678,  0.6774, -1.4240, -0.2390,  0.4030,\n",
       "          0.8914,  0.6256],\n",
       "        [-0.1859, -0.6508,  2.4702, -1.5169, -0.1747, -0.2796,  0.2066, -0.6314,\n",
       "         -1.5557, -0.9266],\n",
       "        [ 0.8525,  0.6308, -1.0572,  0.2850,  0.0799, -0.0070,  0.5361,  1.3133,\n",
       "         -0.7170,  0.2478],\n",
       "        [-0.0264, -2.0029,  1.9462,  0.5551, -1.1980,  0.5827,  0.1759, -1.1432,\n",
       "          0.1153,  0.8533],\n",
       "        [-0.2644, -1.0803, -1.4489,  0.4436,  0.1144,  0.5008, -1.5378, -0.1278,\n",
       "          0.3423,  0.7784],\n",
       "        [-0.9738,  1.3174, -1.1133, -0.5876, -0.4511, -0.6885,  1.4368, -1.3715,\n",
       "         -1.2926, -0.4498],\n",
       "        [ 0.7872,  1.4167, -0.8122, -0.3608,  0.2457, -1.7937, -0.0189, -0.1416,\n",
       "          1.7371,  0.5783]])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = torch.randn(100, 10)  # Example: 100 samples with 10 features\n",
    "mean_centered_data = data - data.mean(dim=0)\n",
    "mean_centered_data[:10]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f8754f9-e73e-41df-b0cb-d083159010f5",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-10-10T04:19:53.158284Z",
     "iopub.status.busy": "2023-10-10T04:19:53.157801Z",
     "iopub.status.idle": "2023-10-10T04:19:53.165560Z",
     "shell.execute_reply": "2023-10-10T04:19:53.163794Z",
     "shell.execute_reply.started": "2023-10-10T04:19:53.158249Z"
    },
    "tags": []
   },
   "source": [
    "## 3. Compute Singular Value Decomposition (SVD)\n",
    "\n",
    "SVD is a matrix factorization technique. PyTorch provides a convenient function for this, which we'll use next.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "24905de4-c035-4827-bc6b-265c66deba48",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-10-10T04:41:56.686129Z",
     "iopub.status.busy": "2023-10-10T04:41:56.685590Z",
     "iopub.status.idle": "2023-10-10T04:41:56.693814Z",
     "shell.execute_reply": "2023-10-10T04:41:56.693142Z",
     "shell.execute_reply.started": "2023-10-10T04:41:56.686104Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[-5.5877e-02,  9.3999e-02,  2.8129e-02, -5.5441e-02, -2.1978e-01,\n",
       "          -1.6222e-01, -8.9302e-02,  4.6909e-02,  8.7238e-02,  2.5380e-01],\n",
       "         [-1.4189e-01, -1.8933e-04,  6.8473e-02, -6.0899e-02,  7.7842e-02,\n",
       "           1.5352e-01, -1.3038e-01, -3.4674e-03, -5.7026e-02, -3.0391e-02],\n",
       "         [ 6.3849e-02,  8.8217e-02,  2.2880e-01,  3.8184e-02,  2.7289e-02,\n",
       "          -6.3581e-02, -9.3603e-02, -1.1781e-01,  1.2020e-01,  3.2058e-02],\n",
       "         [ 1.1140e-01,  8.9035e-03, -1.1009e-01, -1.2803e-01,  4.5352e-02,\n",
       "           2.0290e-03,  5.6940e-02,  1.5093e-02,  8.3337e-03, -1.8379e-02],\n",
       "         [-1.7075e-01,  2.9915e-02, -1.9468e-02,  4.1230e-02,  2.2130e-01,\n",
       "           2.2289e-02,  6.8038e-02, -2.0539e-01, -5.2788e-02,  3.4935e-03],\n",
       "         [-2.6778e-02, -8.5409e-02, -3.7237e-02, -5.4289e-02, -1.0228e-01,\n",
       "           1.0501e-01,  2.5159e-02,  1.1913e-01,  4.6579e-02,  5.9943e-02],\n",
       "         [-1.1396e-01,  1.5030e-01,  1.8968e-01,  1.6944e-02,  4.8597e-02,\n",
       "          -1.3987e-01, -5.0554e-04, -8.3112e-02, -8.6589e-03,  6.5632e-02],\n",
       "         [ 1.0802e-01,  1.1103e-01,  1.3931e-02,  5.9545e-02, -1.4199e-01,\n",
       "           3.0528e-02, -4.3510e-02, -1.5732e-02,  9.2449e-02,  8.1556e-02],\n",
       "         [-3.8357e-02, -1.6153e-01, -1.4260e-01,  2.4639e-03,  5.4267e-02,\n",
       "          -1.2753e-01, -1.3403e-01, -6.7356e-02,  1.1848e-01,  5.6107e-02],\n",
       "         [ 1.7778e-01, -6.5660e-02, -2.4181e-02, -1.5789e-01,  7.3974e-02,\n",
       "          -4.1557e-02,  6.1772e-02,  9.5885e-02,  6.9621e-02, -4.3302e-02]]),\n",
       " tensor([12.1214, 12.0385, 10.7239, 10.4940,  9.6485,  9.2931,  8.8824,  8.3018,\n",
       "          7.8191,  7.1592]),\n",
       " tensor([[ 3.9343e-02, -3.2049e-01,  6.3207e-01, -2.7306e-01,  6.3965e-02,\n",
       "           5.0132e-01,  2.7672e-01,  1.5422e-02,  2.9460e-01,  5.1518e-02],\n",
       "         [ 4.6515e-02, -4.8417e-01, -3.3269e-01, -2.5192e-04,  1.3928e-01,\n",
       "          -9.2822e-02,  9.8021e-02,  3.7889e-01,  3.0412e-01, -6.1568e-01],\n",
       "         [-4.9800e-01,  3.4850e-01,  2.3174e-01, -2.7876e-02,  5.6180e-01,\n",
       "          -5.8514e-02,  2.3136e-01,  2.8276e-02, -2.5358e-01, -3.7200e-01],\n",
       "         [-2.8048e-02,  9.5807e-02,  3.7928e-01,  2.2783e-01, -4.1762e-02,\n",
       "          -1.8302e-02, -4.9179e-01,  7.3773e-01, -4.2518e-02,  6.5502e-02],\n",
       "         [ 1.7585e-01,  1.4152e-01, -1.7541e-01, -3.1810e-01,  5.3811e-02,\n",
       "           5.8589e-01, -5.1333e-01, -1.2988e-01, -2.4446e-01, -3.6165e-01],\n",
       "         [-2.8161e-01, -1.2804e-02,  2.6952e-01,  3.4384e-01, -6.5096e-01,\n",
       "           3.0190e-02, -1.4734e-02, -2.5843e-01, -3.3447e-02, -4.8671e-01],\n",
       "         [-4.1245e-01, -5.0600e-01,  7.2201e-02, -5.1064e-01, -1.0749e-01,\n",
       "          -3.1256e-01, -2.6263e-01, -4.7794e-02, -3.3881e-01,  1.1218e-01],\n",
       "         [-1.5300e-01,  5.8568e-02, -2.9106e-01, -1.0857e-01, -3.5415e-01,\n",
       "           3.4867e-01,  4.9079e-01,  4.5116e-01, -4.1379e-01,  1.1841e-01],\n",
       "         [ 6.5460e-01,  6.8183e-02,  3.1302e-01, -2.1771e-01, -8.8970e-02,\n",
       "          -3.6593e-01,  2.1177e-01,  5.0419e-02, -3.9889e-01, -2.7047e-01],\n",
       "         [-1.2351e-01,  4.9792e-01, -3.0316e-02, -5.7742e-01, -2.9599e-01,\n",
       "          -1.9739e-01, -1.9723e-03,  1.3834e-01,  4.9860e-01, -9.0373e-02]]))"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "U, S, V = torch.svd(mean_centered_data)\n",
    "U[:10], S, V\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db5ca08c-4a15-4283-b029-499a1ba92aa9",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-10-10T04:20:09.173521Z",
     "iopub.status.busy": "2023-10-10T04:20:09.173038Z",
     "iopub.status.idle": "2023-10-10T04:20:09.181098Z",
     "shell.execute_reply": "2023-10-10T04:20:09.179341Z",
     "shell.execute_reply.started": "2023-10-10T04:20:09.173480Z"
    },
    "tags": []
   },
   "source": [
    "## 4. Extract Principal Components\n",
    "\n",
    "The columns of `V` are our principal components. If we aim to reduce our data to a `k`-dimensional space, we simply pick the first `k` columns.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "ed9f4df4-b640-43ee-9a3d-297787853d20",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-10-10T04:42:40.730739Z",
     "iopub.status.busy": "2023-10-10T04:42:40.730425Z",
     "iopub.status.idle": "2023-10-10T04:42:40.736435Z",
     "shell.execute_reply": "2023-10-10T04:42:40.735703Z",
     "shell.execute_reply.started": "2023-10-10T04:42:40.730715Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.0393, -0.3205],\n",
       "        [ 0.0465, -0.4842],\n",
       "        [-0.4980,  0.3485],\n",
       "        [-0.0280,  0.0958],\n",
       "        [ 0.1758,  0.1415],\n",
       "        [-0.2816, -0.0128],\n",
       "        [-0.4124, -0.5060],\n",
       "        [-0.1530,  0.0586],\n",
       "        [ 0.6546,  0.0682],\n",
       "        [-0.1235,  0.4979]])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "k = 2  # Let's reduce to 2 dimensions\n",
    "principal_components = V[:, :k]\n",
    "principal_components\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e82b8fce-65a0-4648-a36f-59ee8f5fcd6f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-10-10T04:20:26.310322Z",
     "iopub.status.busy": "2023-10-10T04:20:26.309861Z",
     "iopub.status.idle": "2023-10-10T04:20:26.316285Z",
     "shell.execute_reply": "2023-10-10T04:20:26.315052Z",
     "shell.execute_reply.started": "2023-10-10T04:20:26.310286Z"
    },
    "tags": []
   },
   "source": [
    "## 5. Project Data onto Principal Components\n",
    "\n",
    "Now, to transform our original data into this new `k`-dimensional space, we'll project it onto the principal components.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "0e7e8dd0-10ab-48c7-a413-4694cd551ce5",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-10-10T04:43:23.331693Z",
     "iopub.status.busy": "2023-10-10T04:43:23.331361Z",
     "iopub.status.idle": "2023-10-10T04:43:23.337631Z",
     "shell.execute_reply": "2023-10-10T04:43:23.336928Z",
     "shell.execute_reply.started": "2023-10-10T04:43:23.331669Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.6773,  1.1316],\n",
       "        [-1.7200, -0.0023],\n",
       "        [ 0.7739,  1.0620],\n",
       "        [ 1.3504,  0.1072],\n",
       "        [-2.0697,  0.3601],\n",
       "        [-0.3246, -1.0282],\n",
       "        [-1.3813,  1.8094],\n",
       "        [ 1.3093,  1.3367],\n",
       "        [-0.4649, -1.9445],\n",
       "        [ 2.1549, -0.7904]])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "projected_data = torch.mm(mean_centered_data, principal_components)\n",
    "projected_data[:10]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91238147-0d5d-4bd7-ae6f-7128f522c0ff",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-10-10T04:20:53.664445Z",
     "iopub.status.busy": "2023-10-10T04:20:53.664094Z",
     "iopub.status.idle": "2023-10-10T04:20:53.670096Z",
     "shell.execute_reply": "2023-10-10T04:20:53.669073Z",
     "shell.execute_reply.started": "2023-10-10T04:20:53.664417Z"
    },
    "tags": []
   },
   "source": [
    "With these steps, you now have `projected_data`, which is your original dataset represented in a reduced `k`-dimensional space. Choosing the right `k` is crucial. It's often chosen based on the amount of variance you wish to retain. Analyzing the singular values in `S` can help make that decision.\n",
    "\n",
    "And that's it! A straightforward method to perform PCA in PyTorch. Happy coding!\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f084e0d-bf9e-44f4-a99c-0e78e2fbbb84",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
